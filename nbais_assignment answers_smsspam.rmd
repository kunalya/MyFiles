
sms_raw <- read.csv("C:\\Users\\kunalyadav\\Documents\\r_samples\\sms_spam.csv",stringsAsFactors = FALSE)

sms_raw$type <- factor(sms_raw$type)
str(sms_raw)
table(sms_raw$type)
sms_raw$type <- factor(sms_raw$type)
head(sms_raw)
tail(sms_raw)

install.packages("tm")
library(tm)
?Corpus

sms_corpus <- Corpus(VectorSource(sms_raw$text))

print(sms_corpus)
inspect(sms_corpus[1:3])
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2],as.character)
?tm_map

#aligning to lowercase and removing number using tm_map function

sms_corpus_clean<- tm_map(sms_corpus,content_transformer(tolower))
as.character(sms_corpus[[1]])
sms_corpus_clean<- tm_map(sms_corpus_clean,removeNumbers)
inspect(sms_corpus_clean[1:3])

#Filler words such as to,and,but,or are like stopwords
# check the list using stopwords()
#?require(tm) is library(package) and require(package) both load the #namespace of the package with name package and attach it on the #search list. require is designed for use inside other functions; it #returns FALSE and gives a warning (rather than an error as library() #does by default) if the package does not exist.

```{r}
sms_corpus_clean<- tm_map(sms_corpus_clean,removeWords,stopwords())
inspect(sms_corpus_clean[1:3])
require(tm)
sms_corpus_clean<- tm_map(sms_corpus_clean,removePunctuation)
inspect(sms_corpus_clean[1:3])

library(SnowballC)

 #Example wordStem(c("learn", "learned", "learning", "learns"))
?stemDocument
sms_corpus_clean <- tm_map(sms_corpus_clean,stemDocument)
sms_corpus_clean<- tm_map(sms_corpus_clean,stripWhitespace)
inspect(sms_corpus_clean[1:5])
#check the original v/s cleaned samples
inspect(sms_corpus[1:2])
inspect(sms_corpus_clean[1:2])

sms_dtm=DocumentTermMatrix(sms_corpus_clean) 
sms_dtm
#splitting data into testing n training set
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test <- sms_dtm[4170:5574, ]
sms_dtm_train

#sms_raw_train <- sms_raw[1:4180,]
#sms_raw_test <- sms_raw[4181:5574,]

table(sms_dtm_train$type)

sms_train_labels  <-sms_raw[1:4169, ]$type
sms_test_labels <-sms_raw[4170:5574, ]$type
sms_corpus_train<-sms_corpus_clean(sms_train_labels)

# decimal percentage splitting of train n test data
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))

```{r}
##install.packages("wordcloud") use the package for bagging
?wordcloud
library(wordcloud)
```
```{r}
spam <- subset(sms_raw,type=="spam")
ham <- subset(sms_raw,type=="ham")
wordcloud(spam$text,min.freq = 40,scale = c(3,0.5),random.order =FALSE)
wordcloud(ham$text,min.freq = 40,scale= c(3,0.5),random.order = FALSE)

library(tm)
sms_freq_words <- findFreqTerms(sms_dtm_train,5)
str(sms_freq_words)
sms_train <- DocumentTermMatrix(sms_corpus_train,list(sms_freq_words))
sms_train
str(sms_freq_words)
#sms_test <- DocumentTermMatrix(sms_corpus_test,list(sms_freq_words))
#sms_test
```
```{r}

convert_counts <- function(x) 
{
  x <-ifelse(x>0,1,0)
  x <- factor(x , levels = c(0,1), labels=c("No", "YES") )
  return(x)
}
```
```{r}

sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]
sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]

sms_train <- apply(sms_dtm_freq_train , MARGIN=2 , convert_counts)
#sms_train
sms_test <- apply(sms_dtm_freq_test,MARGIN=2,convert_counts)
```
#Training the  model on the data 
```{r}
library(e1071)
sms_classifier <- naiveBayes(sms_train,sms_train_labels)
sms_test_pred <- predict(sms_classifier,sms_test)
library(gmodels)
CrossTable(sms_test_pred,sms_test_labels,prop.chisq=FALSE,prop.t=FALSE,dnn=c('PREDICTED','ACTUAL'))

#our observation  from the cross table is 9 + 20 = 29 of 1450 SMS messages were incorrectly
#classified. 
# 7 out of 1222 ham messages were misidentified as spam
# 21 out of 183 spam messages were incorrectly labeled as ham

```

